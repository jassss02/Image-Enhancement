{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08fc5957",
   "metadata": {},
   "source": [
    "# UnderWater Image Enhancement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d90f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from PIL import Image\n",
    "\n",
    "# Load image\n",
    "image1 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw\\Img1.png')\n",
    "image2 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw\\Img2.png')\n",
    "image3 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw\\Img3.png')\n",
    "image4 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw\\Img4.png')\n",
    "image5 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw\\Img5.png')\n",
    "image6 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw\\Img6.png')\n",
    "image7 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw\\Img7.png')\n",
    "image8 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw\\Img8.png')\n",
    "image9 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw\\Img9.png')\n",
    "image10 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw\\Img10.png')\n",
    "\n",
    "# Load reference images\n",
    "rimage1 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\reference\\RImg1.png')\n",
    "rimage2 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\reference\\RImg2.png')\n",
    "rimage3 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\reference\\RImg3.png')\n",
    "rimage4 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\reference\\RImg4.png')\n",
    "rimage5 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\reference\\RImg5.png')\n",
    "rimage6 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\reference\\RImg6.png')\n",
    "rimage7 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\reference\\RImg7.png')\n",
    "rimage8 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\reference\\RImg8.png')\n",
    "rimage9 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\reference\\RImg9.png')\n",
    "rimage10 = Image.open(r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\reference\\RImg10.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc7f5fe",
   "metadata": {},
   "source": [
    "# Plotting the histograms of each channel of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ccd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_histogram(image):\n",
    "    # Split the R, G and B channels\n",
    "    imageR, imageG, imageB = image.split()\n",
    "    \n",
    "    # Plot the histograms\n",
    "    plt.figure(figsize = (20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Histogram of image\")\n",
    "    plt.plot(imageR.histogram(), color='red') \n",
    "    plt.plot(imageG.histogram(), color='green')\n",
    "    plt.plot(imageB.histogram(), color='blue')\n",
    "    plt.show()\n",
    "\n",
    "plot_histogram(image1)\n",
    "plot_histogram(image2)\n",
    "plot_histogram(image3)\n",
    "plot_histogram(image4)\n",
    "plot_histogram(image5)\n",
    "plot_histogram(image6)\n",
    "plot_histogram(image7)\n",
    "plot_histogram(image8)\n",
    "plot_histogram(image9)\n",
    "plot_histogram(image10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e12db7c",
   "metadata": {},
   "source": [
    "- By plotting channel wise histogram, we observered that red channel is usually concentrated on the left side of the histogram and in cases of images with greenish appearance like the above, blue channel also exhibits the same property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234fb85e",
   "metadata": {},
   "source": [
    "# Plotting R, G, and B components of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436fb5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def channel_split(image):\n",
    "    # Split the R, G and B channels\n",
    "    imageR, imageG, imageB = image.split()\n",
    "    x, y=image.size\n",
    "    Rchannel = np.zeros((y, x, 3), dtype = \"uint8\")\n",
    "    Bchannel = np.zeros((y, x, 3), dtype = \"uint8\")\n",
    "    Gchannel = np.zeros((y, x, 3), dtype = \"uint8\")\n",
    "    # Create individual components image\n",
    "    Rchannel[:, :, 0]= imageR;\n",
    "    Bchannel[:, :, 1]= imageG;\n",
    "    Gchannel[:, :, 2]= imageB;\n",
    "    # Convert array to image\n",
    "    Rchannel = Image.fromarray(Rchannel) \n",
    "    Bchannel = Image.fromarray(Bchannel) \n",
    "    Gchannel = Image.fromarray(Gchannel) \n",
    "    \n",
    "    # Plot R, G and B components\n",
    "    plt.figure(figsize = (20, 20))  \n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title(\"Red Component\")\n",
    "    plt.imshow(Rchannel)\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title(\"Green Component\")\n",
    "    plt.imshow(Bchannel) \n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.title(\"Blue Component\")\n",
    "    plt.imshow(Gchannel) \n",
    "    plt.show()\n",
    "    \n",
    "channel_split(image1)\n",
    "channel_split(image2)\n",
    "channel_split(image3)\n",
    "channel_split(image4)\n",
    "channel_split(image5)\n",
    "channel_split(image6)\n",
    "channel_split(image7)\n",
    "channel_split(image8)\n",
    "channel_split(image9)\n",
    "channel_split(image10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c37a11",
   "metadata": {},
   "source": [
    "- By plotting channel wise RGB image component, we observered that green channel is least degraded channel as compared to Red and Blue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf65f4d",
   "metadata": {},
   "source": [
    "# Color Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a06184",
   "metadata": {},
   "source": [
    "## Step 1: Compensating R and B(when required) channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9fe860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageStat\n",
    "# flag = 0 for Red, Blue Compensation via green channel\n",
    "# flag = 1 for Red Compensation via green channel\n",
    "def compensate_RB(image, flag):\n",
    "    # Splitting the image into R, G and B components\n",
    "    imager, imageg, imageb = image.split()\n",
    "    \n",
    "    # Get maximum and minimum pixel value\n",
    "    minR, maxR = imager.getextrema()\n",
    "    minG, maxG = imageg.getextrema()\n",
    "    minB, maxB = imageb.getextrema()\n",
    "    \n",
    "    # Convert to array\n",
    "    imageR = np.array(imager,np.float64)\n",
    "    imageG = np.array(imageg,np.float64)\n",
    "    imageB = np.array(imageb,np.float64)\n",
    "    \n",
    "    x,y = image.size\n",
    "    \n",
    "    # Normalizing the pixel value to range (0, 1)\n",
    "    for i in range(0, y):\n",
    "        for j in range(0, x):\n",
    "            imageR[i][j]=(imageR[i][j]-minR)/(maxR-minR)\n",
    "            imageG[i][j]=(imageG[i][j]-minG)/(maxG-minG)\n",
    "            imageB[i][j]=(imageB[i][j]-minB)/(maxB-minB)\n",
    "    \n",
    "    # Getting the mean of each channel\n",
    "    meanR=np.mean(imageR)\n",
    "    meanG=np.mean(imageG)\n",
    "    meanB=np.mean(imageB)\n",
    "    \n",
    "\n",
    "    # Compensate Red and Blue channel\n",
    "    if flag == 0:\n",
    "        for i in range(y):\n",
    "            for j in range(x):\n",
    "                imageR[i][j]=int((imageR[i][j]+(meanG-meanR)*(1-imageR[i][j])*imageG[i][j])*maxR)\n",
    "                imageB[i][j]=int((imageB[i][j]+(meanG-meanB)*(1-imageB[i][j])*imageG[i][j])*maxB)\n",
    "\n",
    "        # Scaling the pixel values back to the original range\n",
    "        for i in range(0, y):\n",
    "            for j in range(0, x):\n",
    "                imageG[i][j]=int(imageG[i][j]*maxG)\n",
    "   \n",
    "    # Compensate Red channel\n",
    "    if flag == 1:\n",
    "        for i in range(y):\n",
    "            for j in range(x):\n",
    "                imageR[i][j]=int((imageR[i][j]+(meanG-meanR)*(1-imageR[i][j])*imageG[i][j])*maxR)\n",
    "\n",
    "        # Scaling the pixel values back to the original range\n",
    "        for i in range(0, y):\n",
    "            for j in range(0, x):\n",
    "                imageB[i][j]=int(imageB[i][j]*maxB)\n",
    "                imageG[i][j]=int(imageG[i][j]*maxG)\n",
    "            \n",
    "    # Create the compensated image\n",
    "    compensateIm = np.zeros((y, x, 3), dtype = \"uint8\")\n",
    "    compensateIm[:, :, 0]= imageR;\n",
    "    compensateIm[:, :, 1]= imageG;\n",
    "    compensateIm[:, :, 2]= imageB;\n",
    "    \n",
    "    # Plotting the compensated image\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"RB Compensated Image\")\n",
    "    plt.imshow(compensateIm) \n",
    "    plt.show()\n",
    "    compensateIm=Image.fromarray(compensateIm)\n",
    "    \n",
    "    return compensateIm\n",
    "\n",
    "compensatedimage1=compensate_RB(image1, 0)\n",
    "compensatedimage2=compensate_RB(image2, 0)\n",
    "compensatedimage3=compensate_RB(image3, 0)\n",
    "compensatedimage4=compensate_RB(image4, 0)\n",
    "compensatedimage5=compensate_RB(image5, 0)\n",
    "compensatedimage6=compensate_RB(image6, 0)\n",
    "compensatedimage7=compensate_RB(image7, 0)\n",
    "compensatedimage8=compensate_RB(image8, 0)\n",
    "compensatedimage9=compensate_RB(image9, 0)\n",
    "compensatedimage10=compensate_RB(image10, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d17c6",
   "metadata": {},
   "source": [
    "## Step 2: White balancing using Gray World Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029549a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_world(image):\n",
    "    # Splitting the image into R, G and B components\n",
    "    imager, imageg, imageb = image.split()\n",
    "    \n",
    "    # Form a grayscale image\n",
    "    imagegray=image.convert('L')\n",
    "    \n",
    "    # Convert to array\n",
    "    imageR = np.array(imager,np.float64)\n",
    "    imageG = np.array(imageg,np.float64)\n",
    "    imageB = np.array(imageb,np.float64)\n",
    "    imageGray=np.array(imagegray, np.float64)\n",
    "    \n",
    "    x,y = image.size\n",
    "    \n",
    "    # Get mean value of pixels     \n",
    "    meanR=np.mean(imageR)\n",
    "    meanG=np.mean(imageG)\n",
    "    meanB=np.mean(imageB)\n",
    "    meanGray=np.mean(imageGray)\n",
    "    \n",
    "    # Gray World Algorithm  \n",
    "    for i in range(0, y):\n",
    "        for j in range(0, x):\n",
    "            imageR[i][j]=int(imageR[i][j]*meanGray/meanR)\n",
    "            imageG[i][j]=int(imageG[i][j]*meanGray/meanG)\n",
    "            imageB[i][j]=int(imageB[i][j]*meanGray/meanB)\n",
    "    \n",
    "    # Create the white balanced image\n",
    "    whitebalancedIm = np.zeros((y, x, 3), dtype = \"uint8\")\n",
    "    whitebalancedIm[:, :, 0]= imageR;\n",
    "    whitebalancedIm[:, :, 1]= imageG;\n",
    "    whitebalancedIm[:, :, 2]= imageB;\n",
    "    \n",
    "    # Plotting the compensated image\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Compensated Image\")\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"White Balanced Image\")\n",
    "    plt.imshow(whitebalancedIm) \n",
    "    plt.show()\n",
    "    \n",
    "    return Image.fromarray(whitebalancedIm)\n",
    "\n",
    "whitebalanced1=gray_world(compensatedimage1)\n",
    "whitebalanced2=gray_world(compensatedimage2)\n",
    "whitebalanced3=gray_world(compensatedimage3)\n",
    "whitebalanced4=gray_world(compensatedimage4)\n",
    "whitebalanced5=gray_world(compensatedimage5)\n",
    "whitebalanced6=gray_world(compensatedimage6)\n",
    "whitebalanced7=gray_world(compensatedimage7)\n",
    "whitebalanced8=gray_world(compensatedimage8)\n",
    "whitebalanced9=gray_world(compensatedimage9)\n",
    "whitebalanced10=gray_world(compensatedimage10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c9473",
   "metadata": {},
   "source": [
    "# Image Sharpening Of White Balanced Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68077967",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Perform unsharp masking K=1\n",
    "def sharpen(wbimage, original):\n",
    "    # First find the smoothed image using Gaussian filter\n",
    "    smoothed_image = wbimage.filter(ImageFilter.GaussianBlur)\n",
    "    \n",
    "    # Split the smoothed image into R, G and B channel\n",
    "    smoothedr, smoothedg, smoothedb = smoothed_image.split()\n",
    "    \n",
    "    # Split the input image \n",
    "    imager, imageg, imageb = wbimage.split()\n",
    "    \n",
    "    # Convert image to array\n",
    "    imageR = np.array(imager,np.float64)\n",
    "    imageG = np.array(imageg,np.float64)\n",
    "    imageB = np.array(imageb,np.float64)\n",
    "    smoothedR = np.array(smoothedr,np.float64)\n",
    "    smoothedG = np.array(smoothedg,np.float64)\n",
    "    smoothedB = np.array(smoothedb,np.float64)\n",
    "    \n",
    "    x, y=wbimage.size\n",
    "    \n",
    "    # Perform unsharp masking \n",
    "    for i in range(y):\n",
    "        for j in range(x):\n",
    "            imageR[i][j]=2*imageR[i][j]-smoothedR[i][j]\n",
    "            imageG[i][j]=2*imageG[i][j]-smoothedG[i][j]\n",
    "            imageB[i][j]=2*imageB[i][j]-smoothedB[i][j]\n",
    "    \n",
    "    # Create sharpened image\n",
    "    sharpenIm = np.zeros((y, x, 3), dtype = \"uint8\")         \n",
    "    sharpenIm[:, :, 0]= imageR;\n",
    "    sharpenIm[:, :, 1]= imageG;\n",
    "    sharpenIm[:, :, 2]= imageB; \n",
    "    \n",
    "    # Plotting the sharpened image\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"White Balanced Image\")\n",
    "    plt.imshow(wbimage)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Sharpened Image\")\n",
    "    plt.imshow(sharpenIm) \n",
    "    plt.show()\n",
    "    \n",
    "    return Image.fromarray(sharpenIm)\n",
    "\n",
    "sharpenedimage1=sharpen(whitebalanced1, image1)\n",
    "sharpenedimage2=sharpen(whitebalanced2, image2)\n",
    "sharpenedimage3=sharpen(whitebalanced3, image3)\n",
    "sharpenedimage4=sharpen(whitebalanced4, image4)\n",
    "sharpenedimage5=sharpen(whitebalanced5, image5)\n",
    "sharpenedimage6=sharpen(whitebalanced6, image6)\n",
    "sharpenedimage7=sharpen(whitebalanced7, image7)\n",
    "sharpenedimage8=sharpen(whitebalanced8, image8)\n",
    "sharpenedimage9=sharpen(whitebalanced9, image9)\n",
    "sharpenedimage10=sharpen(whitebalanced10, image10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0d1da",
   "metadata": {},
   "source": [
    "# Contrast enhancement of white balanced image by Global Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e151a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "def hsv_global_equalization(image):\n",
    "    # Convert to HSV\n",
    "    hsvimage = image.convert('HSV')\n",
    "   \n",
    "    # Plot HSV Image\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"White balanced Image\")\n",
    "    plt.imshow(hsvimage)\n",
    "    \n",
    "    # Splitting the Hue, Saturation and Value Component \n",
    "    Hue, Saturation, Value = hsvimage.split()\n",
    "    # Perform Equalization on Value Component\n",
    "    equalizedValue = ImageOps.equalize(Value, mask = None)\n",
    "\n",
    "    x, y = image.size\n",
    "    # Create the equalized Image\n",
    "    equalizedIm = np.zeros((y, x, 3), dtype = \"uint8\")\n",
    "    equalizedIm[:, :, 0]= Hue;\n",
    "    equalizedIm[:, :, 1]= Saturation;\n",
    "    equalizedIm[:, :, 2]= equalizedValue;\n",
    "    \n",
    "    # Convert the array to image\n",
    "    hsvimage = Image.fromarray(equalizedIm, 'HSV') \n",
    "    # Convert to RGB\n",
    "    rgbimage = hsvimage.convert('RGB')\n",
    "    \n",
    "    # Plot equalized image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Contrast enhanced Image\")\n",
    "    plt.imshow(rgbimage)\n",
    "    \n",
    "    return rgbimage\n",
    "\n",
    "contrastenhanced1 = hsv_global_equalization(whitebalanced1)\n",
    "contrastenhanced2 = hsv_global_equalization(whitebalanced2)\n",
    "contrastenhanced3 = hsv_global_equalization(whitebalanced3)\n",
    "contrastenhanced4 = hsv_global_equalization(whitebalanced4)\n",
    "contrastenhanced5 = hsv_global_equalization(whitebalanced5)\n",
    "contrastenhanced6 = hsv_global_equalization(whitebalanced6)\n",
    "contrastenhanced7 = hsv_global_equalization(whitebalanced7)\n",
    "contrastenhanced8 = hsv_global_equalization(whitebalanced8)\n",
    "contrastenhanced9 = hsv_global_equalization(whitebalanced9)\n",
    "contrastenhanced10 = hsv_global_equalization(whitebalanced10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c60cc",
   "metadata": {},
   "source": [
    "# Fusion of sharpened image and contrast enhanced image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c938008",
   "metadata": {},
   "source": [
    "## Using averaging method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_fusion(image1, image2):\n",
    "    # Split the images in R, G, B components\n",
    "    image1r, image1g, image1b = image1.split()\n",
    "    image2r, image2g, image2b = image2.split()\n",
    "    \n",
    "    # Convert to array\n",
    "    image1R = np.array(image1r, np.float64)\n",
    "    image1G = np.array(image1g, np.float64)\n",
    "    image1B = np.array(image1b, np.float64)\n",
    "    image2R = np.array(image2r, np.float64)\n",
    "    image2G = np.array(image2g, np.float64)\n",
    "    image2B = np.array(image2b, np.float64)\n",
    "    \n",
    "    x, y = image1R.shape\n",
    "    \n",
    "    # Perform fusion by averaging the pixel values\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            image1R[i][j]= int((image1R[i][j]+image2R[i][j])/2)\n",
    "            image1G[i][j]= int((image1G[i][j]+image2G[i][j])/2)\n",
    "            image1B[i][j]= int((image1B[i][j]+image2B[i][j])/2)\n",
    "    \n",
    "    # Create the fused image\n",
    "    fusedIm = np.zeros((x, y, 3), dtype = \"uint8\")\n",
    "    fusedIm[:, :, 0]= image1R;\n",
    "    fusedIm[:, :, 1]= image1G;\n",
    "    fusedIm[:, :, 2]= image1B;\n",
    "    \n",
    "    # Plot the fused image\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Sharpened Image\")\n",
    "    plt.imshow(image1)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Contrast Enhanced Image\")\n",
    "    plt.imshow(image2)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Average Fused Image\")\n",
    "    plt.imshow(fusedIm) \n",
    "    plt.show()\n",
    "    \n",
    "    return Image.fromarray(fusedIm)\n",
    "    \n",
    "averagefused1 =  average_fusion(sharpenedimage1, contrastenhanced1)\n",
    "averagefused2 =  average_fusion(sharpenedimage2, contrastenhanced2)\n",
    "averagefused3 =  average_fusion(sharpenedimage3, contrastenhanced3)\n",
    "averagefused4 =  average_fusion(sharpenedimage4, contrastenhanced4)\n",
    "averagefused5 =  average_fusion(sharpenedimage5, contrastenhanced5)\n",
    "averagefused6 =  average_fusion(sharpenedimage6, contrastenhanced6)\n",
    "averagefused7 =  average_fusion(sharpenedimage7, contrastenhanced7)\n",
    "averagefused8 =  average_fusion(sharpenedimage8, contrastenhanced8)\n",
    "averagefused9 =  average_fusion(sharpenedimage9, contrastenhanced9)\n",
    "averagefused10 =  average_fusion(sharpenedimage10, contrastenhanced10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0aae31",
   "metadata": {},
   "source": [
    "## Using Principal Component Analysis(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651aa815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_fusion(image1, image2):\n",
    "    # Split the images in R, G, B components\n",
    "    image1r, image1g, image1b = image1.split()\n",
    "    image2r, image2g, image2b = image2.split()\n",
    "    \n",
    "    # Convert to column vector\n",
    "    image1R = np.array(image1r, np.float64).flatten()\n",
    "    image1G = np.array(image1g, np.float64).flatten()\n",
    "    image1B = np.array(image1b, np.float64).flatten()\n",
    "    image2R = np.array(image2r, np.float64).flatten()\n",
    "    image2G = np.array(image2g, np.float64).flatten()\n",
    "    image2B = np.array(image2b, np.float64).flatten()\n",
    "    \n",
    "    # Get mean of each channel\n",
    "    mean1R=np.mean(image1R)\n",
    "    mean1G=np.mean(image1G)\n",
    "    mean1B=np.mean(image1B)\n",
    "    mean2R=np.mean(image2R)\n",
    "    mean2G=np.mean(image2G)\n",
    "    mean2B=np.mean(image2B)\n",
    "    \n",
    "    # Create a 2*N array where each column represents each image channel \n",
    "    imageR=np.array((image1R, image2R))\n",
    "    imageG=np.array((image1G, image2G))\n",
    "    imageB=np.array((image1B, image2B))\n",
    "    \n",
    "    x, y = imageR.shape\n",
    "    \n",
    "    # Subtract the respective mean from each column\n",
    "    for i in range(y):\n",
    "        imageR[0][i]-=mean1R\n",
    "        imageR[1][i]-=mean2R\n",
    "        imageG[0][i]-=mean1G\n",
    "        imageG[1][i]-=mean2G\n",
    "        imageB[0][i]-=mean1B\n",
    "        imageB[1][i]-=mean2B\n",
    "    \n",
    "    # Find the covariance matrix\n",
    "    covR=np.cov(imageR)\n",
    "    covG=np.cov(imageG)\n",
    "    covB=np.cov(imageB)\n",
    "        \n",
    "    # Find eigen value and eigen vector\n",
    "    valueR, vectorR = np.linalg.eig(covR)\n",
    "    valueG, vectorG = np.linalg.eig(covG)\n",
    "    valueB, vectorB = np.linalg.eig(covB)\n",
    "    \n",
    "    # Find the coefficients for each channel which will act as weight for images\n",
    "    if(valueR[0] >= valueR[1]):\n",
    "        coefR=vectorR[:, 0]/sum(vectorR[:, 0])\n",
    "    else:\n",
    "        coefR=vectorR[:, 1]/sum(vectorR[:, 1])\n",
    "    \n",
    "    if(valueG[0] >= valueG[1]):\n",
    "        coefG=vectorG[:, 0]/sum(vectorG[:, 0])\n",
    "    else:\n",
    "        coefG=vectorG[:, 1]/sum(vectorG[:, 1])\n",
    "    \n",
    "    if(valueB[0] >= valueB[1]):\n",
    "        coefB=vectorB[:, 0]/sum(vectorB[:, 0])\n",
    "    else:\n",
    "        coefB=vectorB[:, 1]/sum(vectorB[:, 1])\n",
    "   \n",
    "    # Convert to array\n",
    "    image1R = np.array(image1r, np.float64)\n",
    "    image1G = np.array(image1g, np.float64)\n",
    "    image1B = np.array(image1b, np.float64)\n",
    "    image2R = np.array(image2r, np.float64)\n",
    "    image2G = np.array(image2g, np.float64)\n",
    "    image2B = np.array(image2b, np.float64) \n",
    "    \n",
    "    x, y = image1R.shape\n",
    "    \n",
    "    # Calculate the pixel value for the fused image from the coefficients obtained above\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            image1R[i][j]=int(coefR[0]*image1R[i][j]+coefR[1]*image2R[i][j])\n",
    "            image1G[i][j]=int(coefG[0]*image1G[i][j]+coefG[1]*image2G[i][j])\n",
    "            image1B[i][j]=int(coefB[0]*image1B[i][j]+coefB[1]*image2B[i][j])\n",
    "  \n",
    "    # Create the fused image\n",
    "    fusedIm = np.zeros((x, y, 3), dtype = \"uint8\")\n",
    "    fusedIm[:, :, 0]= image1R;\n",
    "    fusedIm[:, :, 1]= image1G;\n",
    "    fusedIm[:, :, 2]= image1B;\n",
    "    \n",
    "    # Plot the fused image\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Sharpened Image\")\n",
    "    plt.imshow(image1)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Contrast Enhanced Image\")\n",
    "    plt.imshow(image2)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"PCA Fused Image\")\n",
    "    plt.imshow(fusedIm) \n",
    "    plt.show()\n",
    "    \n",
    "    return Image.fromarray(fusedIm)\n",
    " \n",
    "pcafused1 = pca_fusion(sharpenedimage1, contrastenhanced1)\n",
    "pcafused2 = pca_fusion(sharpenedimage2, contrastenhanced2)\n",
    "pcafused3 = pca_fusion(sharpenedimage3, contrastenhanced3)\n",
    "pcafused4 = pca_fusion(sharpenedimage4, contrastenhanced4)\n",
    "pcafused5 = pca_fusion(sharpenedimage5, contrastenhanced5)\n",
    "pcafused6 = pca_fusion(sharpenedimage6, contrastenhanced6)\n",
    "pcafused7 = pca_fusion(sharpenedimage7, contrastenhanced7)\n",
    "pcafused8 = pca_fusion(sharpenedimage8, contrastenhanced8)\n",
    "pcafused9 = pca_fusion(sharpenedimage9, contrastenhanced9)\n",
    "pcafused10 = pca_fusion(sharpenedimage10, contrastenhanced10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7fd6e",
   "metadata": {},
   "source": [
    "# Image Quality Assesment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7dcf9",
   "metadata": {},
   "source": [
    "## PSNR & MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f6b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(reference, fused, original):\n",
    "    R2 = np.amax(reference)**2\n",
    "    MSE = np.sum(np.power(np.subtract(reference, original), 2))\n",
    "    MSE /= (reference.size[0] * original.size[1])\n",
    "    PSNR = 10*np.log10(R2/MSE)\n",
    "    \n",
    "    print(\"Reference vs Original-\", \"MSE: \", MSE, \"PSNR:\", PSNR)\n",
    "    \n",
    "    R2 = np.amax(reference)**2\n",
    "    MSE = np.sum(np.power(np.subtract(reference, fused), 2))\n",
    "    MSE /= (reference.size[0] * fused.size[1])\n",
    "    PSNR = 10*np.log10(R2/MSE)\n",
    "    print(\"Reference vs Fused   -\", \"MSE: \", MSE, \"PSNR:\", PSNR)\n",
    "    print('')\n",
    "    \n",
    "print(\"MSE & PSNR of PCA fused image\")\n",
    "psnr(rimage1, pcafused1, image1)\n",
    "psnr(rimage2, pcafused2, image2)\n",
    "psnr(rimage3, pcafused3, image3)\n",
    "psnr(rimage4, pcafused4, image4)\n",
    "psnr(rimage5, pcafused5, image5)\n",
    "psnr(rimage6, pcafused6, image6)\n",
    "psnr(rimage7, pcafused7, image7)\n",
    "psnr(rimage8, pcafused8, image8)\n",
    "psnr(rimage9, pcafused9, image9)\n",
    "psnr(rimage10, pcafused10, image10)\n",
    "\n",
    "print(\"MSE & PSNR of Average fused image\")\n",
    "psnr(rimage1, averagefused1, image1)\n",
    "psnr(rimage2, averagefused2, image2)\n",
    "psnr(rimage3, averagefused3, image3)\n",
    "psnr(rimage4, averagefused4, image4)\n",
    "psnr(rimage5, averagefused5, image5)\n",
    "psnr(rimage6, averagefused6, image6)\n",
    "psnr(rimage7, averagefused7, image7)\n",
    "psnr(rimage8, averagefused8, image8)\n",
    "psnr(rimage9, averagefused9, image9)\n",
    "psnr(rimage10, averagefused10, image10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f16123",
   "metadata": {},
   "source": [
    "# UnderWater Image Enhancement Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag = 0 for Red, Blue Compensation via green channel\n",
    "# flag = 1 for Red Compensation via green channel\n",
    "def underwater_image_enhancement(image, refimage, flag):\n",
    "    # Plotting histogram\n",
    "    plot_histogram(image)\n",
    "    # Splitting the channel to get R, G, B components of image\n",
    "    channel_split(image)\n",
    "    # Compensate image based on flag\n",
    "    compensatedimage=compensate_RB(image, flag)\n",
    "    # Apply gray world algorithm to complete color correction\n",
    "    whitebalanced=gray_world(compensatedimage)\n",
    "    # Plot histogram of color corrected image\n",
    "    plot_histogram(whitebalanced)\n",
    "    # Perform contrast enhancement using global Histogram Equalization\n",
    "    contrastenhanced = hsv_global_equalization(whitebalanced)\n",
    "    # Perform Unsharp Masking to sharpen the color corrected image\n",
    "    sharpenedimage=sharpen(whitebalanced, image)\n",
    "    # Perform avergaing-based fusion of sharpenend image & contrast enhanced image\n",
    "    averagefused =  average_fusion(sharpenedimage, contrastenhanced)\n",
    "    # Perform PCA-based fusion of sharpenend image & contrast enhanced image\n",
    "    pcafused = pca_fusion(sharpenedimage, contrastenhanced)\n",
    "    # Splitting the channel to get R, G, B components of image\n",
    "    channel_split(averagefused)\n",
    "    # Splitting the channel to get R, G, B components of image\n",
    "    channel_split(pcafused)\n",
    "    \n",
    "    print(\"MSE & PSNR of PCA fused image\")\n",
    "    psnr(refimage, pcafused, image)\n",
    "    print(\"MSE & PSNR of Average fused image\")\n",
    "    psnr(refimage, averagefused, image)\n",
    "    return pcafused, averagefused"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacf1c45",
   "metadata": {},
   "source": [
    "# Performing Results for Other Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cfe56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafused1, averagefused1 = underwater_image_enhancement(image1, rimage1, 0)\n",
    "pcafused1.save('dataset/results/pcafused1.png')\n",
    "averagefused1.save('dataset/results/averagefused1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafused2, averagefused2 = underwater_image_enhancement(image2, rimage2, 0)\n",
    "pcafused2.save('dataset/results/pcafused2.png')\n",
    "averagefused2.save('dataset/results/averagefused2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc983f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafused3, averagefused3 = underwater_image_enhancement(image3, rimage3, 0)\n",
    "pcafused3.save('dataset/results/pcafused3.png')\n",
    "averagefused3.save('dataset/results/averagefused3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafused4, averagefused4 = underwater_image_enhancement(image4, rimage4, 0)\n",
    "pcafused4.save('dataset/results/pcafused4.png')\n",
    "averagefused4.save('dataset/results/averagefused4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafused5, averagefused5 = underwater_image_enhancement(image5, rimage5, 0)\n",
    "pcafused5.save('dataset/results/pcafused5.png')\n",
    "averagefused5.save('dataset/results/averagefused5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ec803",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafused6, averagefused6 = underwater_image_enhancement(image6, rimage6, 0)\n",
    "pcafused6.save('dataset/results/pcafused6.png')\n",
    "averagefused6.save('dataset/results/averagefused6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafused7, averagefused7 = underwater_image_enhancement(image7, rimage7, 0)\n",
    "pcafused7.save('dataset/results/pcafused7.png')\n",
    "averagefused7.save('dataset/results/averagefused7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafused8, averagefused8 = underwater_image_enhancement(image8, rimage8, 0)\n",
    "pcafused8.save('dataset/results/pcafused8.png')\n",
    "averagefused8.save('dataset/results/averagefused8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f033f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafused9, averagefused9 = underwater_image_enhancement(image9, rimage9, 0)\n",
    "pcafused9.save('dataset/results/pcafused9.png')\n",
    "averagefused9.save('dataset/results/averagefused9.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e720eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafused10, averagefused10 = underwater_image_enhancement(image10, rimage10, 0)\n",
    "pcafused10.save('dataset/results/pcafused10.png')\n",
    "averagefused10.save('dataset/results/averagefused10.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb96665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Define the model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Load the weights of the model\n",
    "checkpoint = torch.load('resnet18_weights.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Get the true labels of the test data\n",
    "true_labels = r'C:\\Users\\Jasmehr\\Downloads\\DSML-Jass\\dataset\\raw'\n",
    "\n",
    "# Make predictions using the model on the test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions += preds.cpu().tolist()\n",
    "\n",
    "# Create the confusion matrix\n",
    "confusion_mat = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d4bdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
